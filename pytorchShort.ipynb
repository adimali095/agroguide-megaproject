{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSgfn/Cqq+Nz8yFxeo5t02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adimali095/agroguide-megaproject/blob/main/pytorchShort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "FM3t1WQuVEAj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(1)\n",
        "print(x)\n",
        "x = torch.empty(3)\n",
        "print(x)\n",
        "x = torch.empty(3,3)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnDBjIpNVK_d",
        "outputId": "41c497b5-e277-4887-a432-8331d1665013"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.5410e+35])\n",
            "tensor([-1.5410e+35,  4.5817e-41, -1.5410e+35])\n",
            "tensor([[ 6.6884e+31,  3.2925e-41,  4.3832e+31],\n",
            "        [ 3.2925e-41,  4.4842e-44,  0.0000e+00],\n",
            "        [ 6.7262e-44,  0.0000e+00, -1.6512e-02]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJAWD_Z4VUEd",
        "outputId": "217fba34-d8ca-4ed9-b453-c73cd00ed796"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3264])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(1)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4zeJKmVVYN-",
        "outputId": "ca06b0ae-2fd9-40c9-a700-d72c94260ade"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(1)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFHE320tWAfb",
        "outputId": "eddd3c55-bef2-402b-d64c-6477e3315b50"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.size(),x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrJFvLOhWDaj",
        "outputId": "173f66a5-9ed3-4fbb-fde2-e0a5ad096d63"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1]) torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8PNKe8mWmiz",
        "outputId": "cbfb16ca-c788-49d5-cdb3-c7b29869ae26"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(torch.rand(5),requires_grad = True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn_tZJNUWpwq",
        "outputId": "b00d1020-4ad7-4b62-ca4f-c530ce9b1423"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-153-2f36be730835>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(torch.rand(5),requires_grad = True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1520, 0.6517, 0.8072, 0.9744, 0.2807], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4,4)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwXFn2_NYNeI",
        "outputId": "d9702948-8247-4c19-e9a8-70c0f4939145"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3418, 0.2752, 0.7498, 0.2549],\n",
              "        [0.3787, 0.3492, 0.9741, 0.3253],\n",
              "        [0.3560, 0.9379, 0.4900, 0.5052],\n",
              "        [0.2509, 0.3725, 0.4092, 0.1452]])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.view(2,-1)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722jm-JXZOnG",
        "outputId": "40994f0e-b424-4c44-ef1d-0634ef77a9c6"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3418, 0.2752, 0.7498, 0.2549, 0.3787, 0.3492, 0.9741, 0.3253],\n",
              "        [0.3560, 0.9379, 0.4900, 0.5052, 0.2509, 0.3725, 0.4092, 0.1452]])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = x.numpy()\n",
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF-tvImTZVtu",
        "outputId": "29695d42-81f2-4365-f2b8-d44cbb1b806f"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.34177774, 0.27518684, 0.7497692 , 0.25486124],\n",
              "       [0.37868017, 0.34920436, 0.9741259 , 0.3253485 ],\n",
              "       [0.3560065 , 0.93789375, 0.49001122, 0.50518495],\n",
              "       [0.25093615, 0.37253886, 0.4091648 , 0.1451745 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "t = torch.tensor(n).to(device)"
      ],
      "metadata": {
        "id": "j3u_lxtsbVqB"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3uJ5A9scGuP",
        "outputId": "57332e32-b39d-45e1-d91c-7e168d310091"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,requires_grad = True)\n",
        "y = x+2\n",
        "z = x*x\n",
        "a = x/x\n",
        "b = x.mean()\n",
        "print(x,y,z,a,b,sep = \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aut5Gac8cHlI",
        "outputId": "a18ffb27-bc14-4d30-8375-257545cb1674"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4421, 0.8487], requires_grad=True)\n",
            "tensor([2.4421, 2.8487], grad_fn=<AddBackward0>)\n",
            "tensor([0.1954, 0.7203], grad_fn=<MulBackward0>)\n",
            "tensor([1., 1.], grad_fn=<DivBackward0>)\n",
            "tensor(0.6454, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M2R9SoddG7H",
        "outputId": "4920f890-3172-46f9-d065-3ddfe6acaedb"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AddBackward0 at 0x7fb80d551ff0>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.backward()\n",
        "x.grad # db/dx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7bzC5wEdKKX",
        "outputId": "7be72c5a-f385-42a4-ced8-f3f2159da10e"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5000, 0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2,2)\n",
        "b = (a*a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.grad_fn)\n",
        "a.requires_grad_(True)\n",
        "b = (a*a).sum()\n",
        "print(a.requires_grad)\n",
        "print(b.requires_grad)\n",
        "print(b.grad_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4xPzu0ieL61",
        "outputId": "303f5095-64e9-455d-9ec6-4a98af73da7e"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "None\n",
            "True\n",
            "True\n",
            "<SumBackward0 object at 0x7fb80d5538e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#three methods :\n",
        "a = torch.tensor([1,1],dtype = torch.float32,requires_grad = True)\n",
        "\n",
        "print(a.requires_grad)\n",
        "\n",
        "\n",
        "# 1 using requires_grad_()\n",
        "a.requires_grad_(False)\n",
        "print(\"REQUIRES GRAD : \")\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "\n",
        "'''\n",
        "requires_grad_():\n",
        "This method is used to modify the requires_grad attribute in-place\n",
        "'''\n",
        "\n",
        "\n",
        "# 2 using detach() function\n",
        "print(\"\\nDETACH() :\")\n",
        "b = a.detach() #return another tensor\n",
        "print(b.requires_grad)\n",
        "'''\n",
        "detach():\n",
        "The detach() method creates a new tensor with the same data\n",
        "but without the gradient computation history.\n",
        "This detached tensor (b) will not contribute\n",
        "to gradient computation when used in further operations.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# 3 wrapping in torch.no_grad()\n",
        "print(\"\\nTORCH.NO_GRAD()\")\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad() :\n",
        "  b = a*a\n",
        "  print(b.requires_grad)\n",
        "'''\n",
        "torch.no_grad():\n",
        "The torch.no_grad() context manager is used to temporarily disable gradient computation.\n",
        "'''\n",
        "\n",
        "\n",
        "#4 wrapping in torch.inference_mode()\n",
        "print(\"\\nTORCH.INFERENCE_MODE\")\n",
        "print(a.requires_grad)\n",
        "with torch.inference_mode() :\n",
        "  b = a*a\n",
        "  print(b.requires_grad)\n",
        "'''\n",
        "torch.inference_mode():\n",
        "Introduced in PyTorch 1.10.0,\n",
        "torch.inference_mode() is similar to torch.no_grad()\n",
        "but also disables certain runtime checks and may optimize the computation\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "et0qboBir7u_",
        "outputId": "6f9dd091-bc2a-4443-d6bd-9e6d262131f1"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "REQUIRES GRAD : \n",
            "False\n",
            "\n",
            "DETACH() :\n",
            "False\n",
            "\n",
            "TORCH.NO_GRAD()\n",
            "True\n",
            "False\n",
            "\n",
            "TORCH.INFERENCE_MODE\n",
            "True\n",
            "False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntorch.inference_mode(): \\nIntroduced in PyTorch 1.10.0, \\ntorch.inference_mode() is similar to torch.no_grad() \\nbut also disables certain runtime checks and may optimize the computation\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Linear regresion***\n",
        "\n",
        "f(x) = w * x + b\n",
        "\n",
        "approximating  \n",
        "f(x) = 2 * x + 0\n",
        "w = 2\n",
        "b = 0"
      ],
      "metadata": {
        "id": "La25M9edz9Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dataset\n",
        "weight =2\n",
        "b =0\n",
        "x = []\n",
        "y = []\n",
        "for i in range(10) :\n",
        "  y.append(weight*i + b)\n",
        "  x.append(i)\n",
        "print(x[:5],y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEUP-PbItd9W",
        "outputId": "83a38abd-7989-424d-c70c-8506b5b5563b"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4] [0, 2, 4, 6, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(x,dtype = torch.float32)\n",
        "Y = torch.tensor(y,dtype = torch.float32)\n",
        "W = torch.tensor(0.0,dtype = torch.float32,requires_grad=True)\n",
        "\n",
        "#model output\n",
        "def forward(X) :\n",
        "  return W * X\n",
        "\n",
        "#loss = MSE (Mean Squared Error)\n",
        "def loss(y,y_pred) :\n",
        "  return ((y-y_pred)**2).mean()\n",
        "\n",
        "X_test = 5.0\n",
        "print(\"Prediction BEFORE training : \",forward(X_test).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kf-YLHe0wko",
        "outputId": "081b369e-cd40-4466-ba4f-408b8c20a903"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction BEFORE training :  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs) :\n",
        "\n",
        "  #predict forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  #loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #calculate gradients\n",
        "  l.backward()\n",
        "\n",
        "  with torch.no_grad() :\n",
        "    W -= learning_rate * W.grad\n",
        "  W.grad.zero_()\n",
        "\n",
        "  if(epoch % 10 == 0) :\n",
        "    print(\"epoch : \",epoch,\"\\tw = \",W.item(),\"\\tloss = \",l.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka9_DyaV1MJe",
        "outputId": "cb606e71-bd0a-4a40-befb-7464004dc3fd"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch :  0 \tw =  1.1399999856948853 \tloss =  114.0\n",
            "epoch :  10 \tw =  1.9998141527175903 \tloss =  5.32592002855381e-06\n",
            "epoch :  20 \tw =  2.0 \tloss =  7.801759455486335e-13\n",
            "epoch :  30 \tw =  2.0 \tloss =  0.0\n",
            "epoch :  40 \tw =  2.0 \tloss =  0.0\n",
            "epoch :  50 \tw =  2.0 \tloss =  0.0\n",
            "epoch :  60 \tw =  2.0 \tloss =  0.0\n",
            "epoch :  70 \tw =  2.0 \tloss =  0.0\n",
            "epoch :  80 \tw =  2.0 \tloss =  0.0\n",
            "epoch :  90 \tw =  2.0 \tloss =  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(forward(X_test).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70E4gr3f4aja",
        "outputId": "dc1609fc-5146-4ca3-a6a6-cc59c09cd32a"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xTijvGxm5JAi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}